{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bedb2ed9-6988-4ffd-b193-6556e9e6a1f6",
   "metadata": {},
   "source": [
    "### Import our essential Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a20be29f-e69f-4d9c-ac7d-af01d05a2a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as nx # NetworkX is a package for the Python programming language that's used to create, manipulate, and study the structure, dynamics, and functions of complex graph networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27df96f9-1a74-4640-84d3-c90cc3bc7040",
   "metadata": {},
   "source": [
    "### Create our function 'Sentences' for a later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b920fa1f-1027-47e1-8fa6-fd3358265483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_article(file_name):\n",
    "    sentences = []\n",
    "    file = open(file_name, 'r') \n",
    "    f_data = file.readlines()\n",
    "    f_data = [x for x in f_data if x != '\\n'] # it should remove any break present\n",
    "    f_data = [x.replace('\\n',' ') for x in f_data] #this would remove that end of line\n",
    "    f_data = ''.join(f_data) \n",
    "    article = f_data.split('. ') \n",
    "    for sentence in article:\n",
    "        sentences.append(sentence.replace(\"^[a-zA-Z0-9!@#$&()-`+,/\\\"]\", \" \").split(\" \"))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eee46c6-c65e-4659-af67-ab674246a0ad",
   "metadata": {},
   "source": [
    "### Define a Cosine Similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "176028e4-1f11-4f3f-aa0e-959fdfa9c7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_similarity_matrix(sentences, stop_words):\n",
    "    similarity_matrix = np.zeros((len(sentences), len(sentences)))  # Create an empty similarity matrix\n",
    "    \n",
    "    for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "            if idx1 == idx2: # ignore if both are same sentences\n",
    "                continue \n",
    "                similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cd5f98-79d8-47f5-9aec-43bb916c8e88",
   "metadata": {},
   "source": [
    "### We start our Algo step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5408e26a-4086-4f9d-a55a-3048da8fca28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes of top ranked_sentence order are  [(0.06666666666666665, ['Therefore,', 'blockchains', 'are', 'resistant', 'to', 'modification', 'of', 'their', 'data', 'because', 'once', 'recorded,', 'the', 'data', 'in', 'any', 'given', 'block', 'cannot', 'be', 'altered', 'retroactively', 'without', 'altering', 'all', 'subsequent', 'blocks']), (0.06666666666666665, ['The', 'timestamp', 'proves', 'that', 'the', 'transaction', 'data', 'existed', 'when', 'the', 'block', 'was', 'published', 'in', 'order', 'to', 'get', 'into', 'its', 'hash']), (0.06666666666666665, ['The', 'invention', 'of', 'the', 'blockchain', 'for', 'bitcoin', 'made', 'it', 'the', 'first', 'digital', 'currency', 'to', 'solve', 'the', 'double-spending', 'problem', 'without', 'the', 'need', 'of', 'a', 'trusted', 'authority', 'or', 'central', 'server']), (0.06666666666666665, ['The', 'identity', 'of', 'Satoshi', 'Nakamoto', 'remains', 'unknown', 'to', 'date']), (0.06666666666666665, ['The', 'blockchain', 'was', 'popularized', 'by', 'a', 'person', '(or', 'group', 'of', 'people)', 'using', 'the', 'name', 'Satoshi', 'Nakamoto', 'in', '2008', 'to', 'serve', 'as', 'the', 'public', 'transaction', 'ledger', 'of', 'the', 'cryptocurrency', 'bitcoin,', 'based', 'on', 'work', 'by', 'Stuart', 'Haber,', 'W']), (0.06666666666666665, ['The', 'blockchain', 'is', 'considered', 'a', 'type', 'of', 'payment', 'rail']), (0.06666666666666665, ['Scott', 'Stornetta,', 'and', 'Dave', 'Bayer']), (0.06666666666666665, ['Private', 'blockchains', 'have', 'been', 'proposed', 'for', 'business', 'use', 'but', 'Computerworld', 'called', 'the', 'marketing', 'of', 'such', 'privatized', 'blockchains', 'without', 'a', 'proper', 'security', 'model', '\"snake', 'oil\"']), (0.06666666666666665, ['However,', 'others', 'have', 'argued', 'that', 'permissioned', 'blockchains,', 'if', 'carefully', 'designed,', 'may', 'be', 'more', 'decentralized', 'and', 'therefore', 'more', 'secure', 'in', 'practice', 'than', 'permissionless', 'ones.']), (0.06666666666666665, ['Each', 'block', 'contains', 'a', 'cryptographic', 'hash', 'of', 'the', 'previous', 'block,', 'a', 'timestamp,', 'and', 'transaction', 'data', '(generally', 'represented', 'as', 'a', 'Merkle', 'tree)']), (0.06666666666666665, ['Blockchains', 'are', 'typically', 'managed', 'by', 'a', 'peer-to-peer', 'network', 'for', 'use', 'as', 'a', 'publicly', 'distributed', 'ledger,', 'where', 'nodes', 'collectively', 'adhere', 'to', 'a', 'protocol', 'to', 'communicate', 'and', 'validate', 'new', 'blocks']), (0.06666666666666665, ['As', 'blocks', 'each', 'contain', 'information', 'about', 'the', 'block', 'previous', 'to', 'it,', 'they', 'form', 'a', 'chain,', 'with', 'each', 'additional', 'block', 'reinforcing', 'the', 'ones', 'before', 'it']), (0.06666666666666665, ['Although', 'blockchain', 'records', 'are', 'not', 'unalterable', 'as', 'forks', 'are', 'possible,', 'blockchains', 'may', 'be', 'considered', 'secure', 'by', 'design', 'and', 'exemplify', 'a', 'distributed', 'computing', 'system', 'with', 'high', 'Byzantine', 'fault', 'tolerance']), (0.06666666666666665, ['A', 'blockchain', 'is', 'a', 'growing', 'list', 'of', 'records,', 'called', 'blocks,', 'that', 'are', 'linked', 'together', 'using', 'cryptography']), (0.06666666666666665, ['', 'The', 'bitcoin', 'design', 'has', 'inspired', 'other', 'applications', 'and', 'blockchains', 'that', 'are', 'readable', 'by', 'the', 'public', 'and', 'are', 'widely', 'used', 'by', 'cryptocurrencies'])]\n",
      "Summarize Text: \n",
      " Therefore, blockchains are resistant to modification of their data because once recorded, the data in any given block cannot be altered retroactively without altering all subsequent blocks. The timestamp proves that the transaction data existed when the block was published in order to get into its hash. The invention of the blockchain for bitcoin made it the first digital currency to solve the double-spending problem without the need of a trusted authority or central server\n"
     ]
    }
   ],
   "source": [
    "def generate_summary(file_name, top_n=5):\n",
    "    \n",
    "    # nltk.download(\"stopwords\")    ### if not already installed, delete the # and run the code one time\n",
    "    stop_words = stopwords.words('english')\n",
    "    summarize_text = []\n",
    "\n",
    "    # Step 1 - Input Article and split it into Sentences\n",
    "    sentences =  read_article(file_name)\n",
    "\n",
    "    # Step 2 - Build a Similary Martix across sentences & remove Stop Words\n",
    "    sentence_similarity_martix = build_similarity_matrix(sentences, stop_words)\n",
    "\n",
    "    # Step 3 - Generate rank based on Matrix\n",
    "    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)\n",
    "    scores = nx.pagerank(sentence_similarity_graph)\n",
    "\n",
    "    # Step 4 - Sort the rank and pick top sentences\n",
    "    ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
    "    print(\"Indexes of top ranked_sentence order are \", ranked_sentence)    \n",
    "\n",
    "    for i in range(top_n):\n",
    "      summarize_text.append(\" \".join(ranked_sentence[i][1]))\n",
    "\n",
    "    # Step 5 - output the summarized text\n",
    "    print(\"Summarize Text: \\n\", \". \".join(summarize_text))\n",
    "\n",
    "\n",
    "generate_summary(\"Readme_test.txt\",3) # we choose randomly 3 to have the top 3 sentences as output. you can choose more or less also"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
